{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18lB5W2mPeJ9KJ6AITkeEP21527xjtGjV","timestamp":1681170101568},{"file_id":"1yhY-u-oa67TXdpCiI3Uc_KQxUmtHnNyc","timestamp":1680727903565},{"file_id":"1n_BI4jKiIlodu79zqRDoAGL-ieDUPYaj","timestamp":1676493254253},{"file_id":"1tzaxQ4emhHBBiOyq9bQfEEZeSw6FPAiA","timestamp":1676420270381},{"file_id":"1MrC111639eK-cCX3NoD8oyBp_Fg-gvEE","timestamp":1676236127791}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Import Packages"],"metadata":{"id":"22Osd5PRPx6A"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Neem_2_vEIH5","executionInfo":{"status":"ok","timestamp":1681172074991,"user_tz":240,"elapsed":13863,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"outputs":[],"source":["# Introduction to Neural Networks (CSE 40868/60868)\n","# University of Notre Dame, Spring 2023\n","# Final Project Portion 3: Multi Layer Perceptron (MLP) for Genre Classification\n","# Based upon MLP used in Practical 1 (Thomas Summe, Zheng Ning, Adam Czajka, February 2023)\n","# _________________________________________________________________________\n","# Christine Van Kirk, Mia Manabat, Camille Knott (April 2023)\n","\n","import torch\n","import pandas as pd\n","import torch.nn as nn\n","import numpy as np\n","import argparse\n","import math\n","\n","from torch.utils.data import Dataset, random_split, DataLoader\n","from sklearn.preprocessing import LabelEncoder\n"]},{"cell_type":"markdown","source":["# Step 1: Build PyTorch Dataset for Genre Data"],"metadata":{"id":"P44iSjkiP7B4"}},{"cell_type":"code","source":["# dataset class\n","class GenreData(Dataset):\n","    \n","    # constructor for Pytorch dataset class\n","    def __init__(self, path):\n","\n","        # read dataset from path\n","        data = pd.read_csv(path, header=0)\n","        \n","        # instantiate label encoder\n","        le = LabelEncoder()\n","\n","        # numberize the attributed features\n","        for col in data.columns:\n","            data[col] = le.fit(data[col]).transform(data[col])\n","        self.data = data\n","\n","    # returns the number of samples in our dataset\n","    def __len__(self):\n","        return len(self.data)\n","\n","    # loads and returns a sample from the dataset at the given index \"item\"\n","    def __getitem__(self, item):\n","        x = self.data.drop(['genre'], axis=1).values\n","        x = torch.tensor(x).float()\n","\n","        # normalize the data\n","        feat = (x/torch.max(x))[item, :]\n","        y = self.data['genre'].values\n","        label = torch.tensor(y).float().unsqueeze(1)[item, :]\n","\n","        return feat, label"],"metadata":{"id":"AgShgroeHRCc","executionInfo":{"status":"ok","timestamp":1681172074991,"user_tz":240,"elapsed":22,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: Specify Network-Related Hyper-Parameters"],"metadata":{"id":"kCubZ2D6WN5A"}},{"cell_type":"code","source":["data_path = \"ER_EchoNest_AudioFeatures.csv\" # specify location of Genre.csv\n","input_dim = 8               # equal to number of features describing each Genre\n","hidden_dim = 90             # number of hidden neurons\n","output_dim = 1              # number of output neurons\n","device = 'cpu'              # we will be using CPU in this practical\n","batch_size = 200            # specify batch size"],"metadata":{"id":"36idPZ5USUuE","executionInfo":{"status":"ok","timestamp":1681172074991,"user_tz":240,"elapsed":5,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Step 3: Define Model Evaluation Function"],"metadata":{"id":"nwAAUkYDaJ8q"}},{"cell_type":"code","source":["# evaluates the trained model\n","def evaluate(model, loader):\n","\n","    # we need to switch the model into the evaluation mode\n","    model.eval()\n","\n","    # create a list to store the prediction results\n","    res_store = []\n","    for batch in loader:\n","        x, y = batch\n","        \n","        # make a prediction for a data sample \"x\"\n","        pred = model(x)\n","        pred = (pred > 0.5).float().squeeze(1)\n","        y = y.squeeze(1)\n","\n","        # if the prediction is correct, append True; else append False\n","        res_store += (pred == y).tolist()\n","\n","    # return the classification accuracy\n","    acc = sum(res_store)/len(res_store)\n","    return acc"],"metadata":{"id":"KwkEQn4xHpiJ","executionInfo":{"status":"ok","timestamp":1681172074992,"user_tz":240,"elapsed":6,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Step 4: Building The Multi-Layer Perceptron By Hand"],"metadata":{"id":"oIG8nq9dV2pc"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.sigmoid(out)\n","        return out\n","\n"," "],"metadata":{"id":"SkzjTKI7HVrl","executionInfo":{"status":"ok","timestamp":1681172074992,"user_tz":240,"elapsed":5,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Instantiate model and dataset"],"metadata":{"id":"P5yCN18SYQir"}},{"cell_type":"code","source":["# Seed the random number generator for all devices (both CPU and CUDA)\n","torch.manual_seed(0)\n","\n","# Instantiate the dataset\n","data = GenreData(data_path)\n","\n","# Instantiate the MLP model: 22 features (input size), 90 neurons in the hidden layer, and 1 output neuron\n","# (you may experiment with these numbers to see what happens!)\n","mlp = MLP(input_dim, hidden_dim, output_dim)\n","\n","# Here we use torch random_split() function to split the data into training set, validation set and test set \n","# e.g., with the following proportions: 0.6 : 0.2 : 0.2; hint: len(data) will give you number of samples in our dataset\n","# (see https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split)\n","train_set_size = 0.6\n","val_set_size = 0.2\n","test_set_size = 0.2\n","train_set, val_set, test_set = torch.utils.data.random_split(data,[train_set_size,val_set_size,test_set_size])\n","\n","# Wrap the dataset into Pytorch dataloader to pass samples in \"minibatches\"\n","train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n","val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=True, drop_last=False)\n","test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False)\n"],"metadata":{"id":"V844bi-iQOD7","executionInfo":{"status":"ok","timestamp":1681174515185,"user_tz":240,"elapsed":568,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["## Run Randomly-Initialized Network"],"metadata":{"id":"VtrBiNAjYplJ"}},{"cell_type":"code","source":["acc = evaluate(mlp, test_dataloader)\n","print(f\"Test accuracy = {acc}\")"],"metadata":{"id":"U7e229tTnTUV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681174518308,"user_tz":240,"elapsed":2167,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}},"outputId":"03ac0568-a75e-4f1c-ffd3-5fedf03e0660"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy = 0.57125\n"]}]},{"cell_type":"markdown","source":["# Step 5: Training The Multi-Layer Perceptron"],"metadata":{"id":"D-98TuIKZ2cX"}},{"cell_type":"markdown","source":["## Specify Training-Related Hyper-Parameters"],"metadata":{"id":"zWrOdVczaAID"}},{"cell_type":"code","source":["save = \"best_model\"\n","epochs = 20\n","learning_rate = 0.01"],"metadata":{"id":"LTcmSqDgaAeM","executionInfo":{"status":"ok","timestamp":1681174518309,"user_tz":240,"elapsed":4,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Run Training Loop"],"metadata":{"id":"avPeOZI3YY3S"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# define the loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.SGD(mlp.parameters(), lr=0.01)\n","\n","# loop over the dataset for num_epochs epochs\n","acc_best = 0.0\n","for epoch in range(epochs):\n","    print(f\"epoch:{epoch}\")\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(train_dataloader, 0):\n","        # get the inputs and labels\n","        inputs, labels = data\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        # forward + backward + optimize\n","        outputs = mlp(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # evaluate the model \n","    acc = evaluate(mlp, val_dataloader)\n","\n","    if acc > acc_best and save:\n","        torch.save(mlp.state_dict(), save + \"mlp\")\n","\n","    print(f\"Epoch: #{epoch+1}: validation accuracy = {acc*100:.2f}%; loss={loss}\")\n"],"metadata":{"id":"3RGI4Jh5VqBH","executionInfo":{"status":"ok","timestamp":1681174602802,"user_tz":240,"elapsed":83012,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9913a500-5496-4a13-a57e-a09c50155d1f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:0\n","Epoch: #1: validation accuracy = 56.62%; loss=0.685326099395752\n","epoch:1\n","Epoch: #2: validation accuracy = 59.38%; loss=0.6928468346595764\n","epoch:2\n","Epoch: #3: validation accuracy = 63.00%; loss=0.6834285259246826\n","epoch:3\n","Epoch: #4: validation accuracy = 65.12%; loss=0.6811364889144897\n","epoch:4\n","Epoch: #5: validation accuracy = 66.38%; loss=0.6798668503761292\n","epoch:5\n","Epoch: #6: validation accuracy = 67.50%; loss=0.6778132915496826\n","epoch:6\n","Epoch: #7: validation accuracy = 68.88%; loss=0.6723321676254272\n","epoch:7\n","Epoch: #8: validation accuracy = 69.50%; loss=0.6729267835617065\n","epoch:8\n","Epoch: #9: validation accuracy = 70.50%; loss=0.6712745428085327\n","epoch:9\n","Epoch: #10: validation accuracy = 70.38%; loss=0.674710750579834\n","epoch:10\n","Epoch: #11: validation accuracy = 70.50%; loss=0.6611984968185425\n","epoch:11\n","Epoch: #12: validation accuracy = 70.38%; loss=0.6659801006317139\n","epoch:12\n","Epoch: #13: validation accuracy = 71.12%; loss=0.6688480973243713\n","epoch:13\n","Epoch: #14: validation accuracy = 71.12%; loss=0.6554142832756042\n","epoch:14\n","Epoch: #15: validation accuracy = 71.50%; loss=0.6671552062034607\n","epoch:15\n","Epoch: #16: validation accuracy = 71.75%; loss=0.6558500528335571\n","epoch:16\n","Epoch: #17: validation accuracy = 72.38%; loss=0.6530886888504028\n","epoch:17\n","Epoch: #18: validation accuracy = 72.50%; loss=0.6532538533210754\n","epoch:18\n","Epoch: #19: validation accuracy = 72.25%; loss=0.6547002196311951\n","epoch:19\n","Epoch: #20: validation accuracy = 72.62%; loss=0.6469699740409851\n"]}]},{"cell_type":"markdown","source":["## Test The Model (with unknown test data)"],"metadata":{"id":"TrW1v5ASauN_"}},{"cell_type":"code","source":["# Load the modelâ€™s weights\n","mlp.load_state_dict(torch.load(save + \"mlp\"))\n","acc = evaluate(mlp, test_dataloader)\n","print(f\"Test accuracy = {acc}\")"],"metadata":{"id":"6juSZhrDSu4L","executionInfo":{"status":"ok","timestamp":1681174625839,"user_tz":240,"elapsed":2062,"user":{"displayName":"Mia Manabat","userId":"00861892358395082376"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"976b7339-7655-4426-bb0c-a8a0939b3630"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy = 0.715\n"]}]}]}